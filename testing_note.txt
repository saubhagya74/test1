done conversation
create table conversation_(
    conversation_id_ bigint primary key,
    chat_name_ varchar(30),
    last_message_ varchar(15),
    last_time_ timestamptz default CURRENT_TIMESTAMP,
    user_a_id_ bigint not null,
    user_b_id_ bigint not null,
    settings_ jsonb default '{
    "is_pinned_":"false",
    "notification_level_":"all",
    "theme_":"default",
    "direction_": [0,0]
    }'::jsonb
);
done content type enum
////////////
use sqlx::Row; // Needed for .get()

let rows = sqlx::query("SELECT conversation_id_, last_message_ FROM conversations_ WHERE user_a_id_ = $1")
    .bind(id3)
    .fetch_all(&state.db_pool)
    .await
    .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;

let json_list: Vec<serde_json::Value> = rows.iter().map(|row| {
    serde_json::json!({
        "id": row.get::<i64, _>("conversation_id_"),
        "msg": row.get::<Option<String>, _>("last_message_")
    })
}).collect();
let conversation_rows = sqlx::query!(
    "SELECT conversation_id_, chat_name_, last_message_, last_time_ 
     FROM conversations_ 
     WHERE user_a_id_ = $1 OR user_b_id_ = $1 
     ORDER BY last_time_ DESC 
     LIMIT $2",
    id3, 
    10i64
)
.fetch_all(&state.db_pool)
.await
.map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;

// Here, conversation_rows is a Vec of an anonymous internal struct.
// You can turn it into JSON directly:
let response_data = serde_json::to_value(conversation_rows)
    .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?; alwasy use query! or as

    {"action":"sendMessagePrivate","token":{"accesstoken":"thisisatoken"},"payload":{ "sender_id": 7420747096048934897, "receiver_id": 7420747096048934907 ,"content_type": "text", "description":"verylongstring"}}
    
    curl -i  -X POST http://localhost:6745/getRecentMessages   -H "Content-Type: application/json"   -H "id:7420747096048934897" -d '{ "chatid":1001, "timestamp": "2026-02-25T21:30:00Z"}'
    
    {"action":"sendMessagePrivate","token":{"accesstoken":"thisisatoken"},"payload":{ "sender_id": 7420747096048934897, "receiver_id": 7420747096048934907 ,"chat_id":1001,"content_type": "text", "description":"hello bro how y doing??"}}   
    {"action":"sendRequest","token":{"accesstoken":"thisisatoken"},"payload":{ "sender_id": 7420747096048934897, "receiver_id": 7420747096048934907}}   


    -- Note: Always store the smaller ID in user_a to make matching easier
    
    CREATE OR REPLACE FUNCTION insert_private_message(
    p_sender BIGINT, p_receiver BIGINT, p_msg TEXT, ...
) RETURNS VOID AS $$
DECLARE
    v_chat_id BIGINT;
BEGIN
    -- Logic: Find or Create conversation
    INSERT INTO conversation_ (...) VALUES (...)
    ON CONFLICT (...) DO UPDATE ...
    RETURNING chat_id_ INTO v_chat_id;

    -- Logic: Insert Message
    INSERT INTO message_ (chat_id_, ...) VALUES (v_chat_id, ...);
END;
$$ LANGUAGE plpgsql;
ALTER TABLE conversation_ ADD CONSTRAINT unique_user_pair UNIQUE (user_a_id_, user_b_id_);
ALTER TABLE conversation_
ADD CONSTRAINT check_user_order CHECK (user_a_id_ < user_b_id_);
 curl -i -X POST http://localhost:6745/getRecentMessages   -H "Content-Type: application/json"   -H "id:7420747096048934897" -d '{ "chatid": 1001, "timestamp": "2026-01-26T23:59:59Z" }'



begin transaction
make the table1 in memory using those vecs 
make another memtable2 where descroption is trimmed(dont use LEFT it breaks fastness of primary key)
make another memtable3 for updating in conversation( user_a_id , user_b_id_,last_message,last_time)
make another memtable4 for fresh insert in conversation (full convo schema)
take user_a_id_ and user_b_id_ from table2 and check exixtence
on true insert that row into memtable3 for updating
on false insert that row into memtable4 for fresh insert

now bulk unnest UPDATE
         unnest fresh insert
         unnest insert into message_

// Use the "Mega-Query" logic within sqlx
let result = sqlx::query!(
    r#"
    WITH raw_data AS (
        SELECT * FROM UNNEST(
            $1::int8[], $2::int8[], $3::int8[], $4::int8[], 
            $5::text[], $6::text[], $7::timestamptz[], $8::int8[], $9::int8[]
        ) AS t(msg_id, s_id, r_id, new_c_id, content, tri_desc, m_at, u_a, u_b)
    ),
    -- Handle conversations: Insert if missing, Update if exists
    upsert_convo AS (
        INSERT INTO conversation_ (chat_id_, user_a_id_, user_b_id_, last_message_, last_time_)
        SELECT DISTINCT ON (u_a, u_b) 
            new_c_id, u_a, u_b, tri_desc, m_at 
        FROM raw_data
        ON CONFLICT (user_a_id_, user_b_id_) 
        DO UPDATE SET 
            last_message_ = EXCLUDED.last_message_,
            last_time_ = EXCLUDED.last_time_
        RETURNING chat_id_, user_a_id_, user_b_id_
    )
    -- Insert all messages linking to the chat_id from the upsert step
    INSERT INTO message_ (message_id_, chat_id_, sender_id_, receiver_id_, description_, messaged_at_)
    SELECT 
        r.msg_id, u.chat_id_, r.s_id, r.r_id, r.content, r.m_at
    FROM raw_data r
    JOIN upsert_convo u ON r.u_a = u.user_a_id_ AND r.u_b = u.user_b_id_;
    "#,
    &message_ids, &sender_ids, &receiver_ids, &new_chat_ids,
    &descriptions, &trimmed_descriptions, &messaged_ats,
    &user_a_ids, &user_b_ids
).execute(&state.db_pool).await;
Deduplication: In a 500ms window, Alice might send 5 messages to Bob. Your user_a_ids vector will have that pair 5 times. If you don't use DISTINCT ON (u_a, u_b) in your SQL, you will try to insert/update the conversation 5 times for the same pair.